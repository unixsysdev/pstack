interface Env {\n  DB: D1Database;\n  CONTENT_EXTRACTOR_URL: string;\n  CONTENT_PROCESSOR_URL: string;\n  VECTOR_WORKER_URL: string;\n}\n\ninterface TaskRequest {\n  article_id?: number;\n  url?: string;\n  source_name?: string;\n  content_key?: string;\n  analysis_key?: string;\n}\n\nexport default {\n  async fetch(request: Request, env: Env, ctx: ExecutionContext): Promise<Response> {\n    const url = new URL(request.url);\n    \n    if (request.method === 'POST') {\n      const body: TaskRequest = await request.json();\n      \n      switch (url.pathname) {\n        case '/extract':\n          return await handleExtraction(body, env);\n          \n        case '/process':\n          return await handleProcessing(body, env);\n          \n        case '/vectorize':\n          return await handleVectorization(body, env);\n          \n        case '/status':\n          return await getStatus(body, env);\n          \n        case '/retry':\n          return await retryFailed(env);\n          \n        default:\n          return new Response('Unknown endpoint', { status: 404 });\n      }\n    }\n    \n    if (url.pathname === '/health') {\n      return new Response('Orchestrator OK', { status: 200 });\n    }\n    \n    if (url.pathname === '/metrics') {\n      return await getMetrics(env);\n    }\n    \n    return new Response('Intelligence Pipeline Orchestrator', { status: 200 });\n  }\n} satisfies ExportedHandler<Env>;\n\nasync function handleExtraction(body: TaskRequest, env: Env): Promise<Response> {\n  try {\n    if (!body.article_id || !body.url) {\n      return new Response('Missing article_id or url', { status: 400 });\n    }\n    \n    // Log extraction request\n    await env.DB.prepare(`\n      INSERT INTO processing_queue (article_id, task_type, status, created_at)\n      VALUES (?, 'extract', 'processing', ?)\n    `).bind(\n      body.article_id,\n      new Date().toISOString()\n    ).run();\n    \n    // Forward to content extractor\n    const response = await fetch(env.CONTENT_EXTRACTOR_URL + '/extract', {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify(body)\n    });\n    \n    if (response.ok) {\n      return new Response('Extraction initiated', { status: 200 });\n    } else {\n      await logError(body.article_id, 'extract', await response.text(), env);\n      return new Response('Extraction failed', { status: 500 });\n    }\n  } catch (error) {\n    console.error('Extraction orchestration failed:', error);\n    await logError(body.article_id, 'extract', String(error), env);\n    return new Response('Extraction orchestration failed', { status: 500 });\n  }\n}\n\nasync function handleProcessing(body: TaskRequest, env: Env): Promise<Response> {\n  try {\n    if (!body.article_id || !body.content_key) {\n      return new Response('Missing article_id or content_key', { status: 400 });\n    }\n    \n    // Log processing request\n    await env.DB.prepare(`\n      INSERT INTO processing_queue (article_id, task_type, status, created_at)\n      VALUES (?, 'process', 'processing', ?)\n    `).bind(\n      body.article_id,\n      new Date().toISOString()\n    ).run();\n    \n    // Forward to content processor\n    const response = await fetch(env.CONTENT_PROCESSOR_URL + '/process', {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify(body)\n    });\n    \n    if (response.ok) {\n      return new Response('Processing initiated', { status: 200 });\n    } else {\n      await logError(body.article_id, 'process', await response.text(), env);\n      return new Response('Processing failed', { status: 500 });\n    }\n  } catch (error) {\n    console.error('Processing orchestration failed:', error);\n    await logError(body.article_id, 'process', String(error), env);\n    return new Response('Processing orchestration failed', { status: 500 });\n  }\n}\n\nasync function handleVectorization(body: TaskRequest, env: Env): Promise<Response> {\n  try {\n    if (!body.article_id) {\n      return new Response('Missing article_id', { status: 400 });\n    }\n    \n    // Log vectorization request\n    await env.DB.prepare(`\n      INSERT INTO processing_queue (article_id, task_type, status, created_at)\n      VALUES (?, 'vectorize', 'processing', ?)\n    `).bind(\n      body.article_id,\n      new Date().toISOString()\n    ).run();\n    \n    // Forward to vector worker\n    const response = await fetch(env.VECTOR_WORKER_URL + '/vectorize', {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify(body)\n    });\n    \n    if (response.ok) {\n      return new Response('Vectorization initiated', { status: 200 });\n    } else {\n      await logError(body.article_id, 'vectorize', await response.text(), env);\n      return new Response('Vectorization failed', { status: 500 });\n    }\n  } catch (error) {\n    console.error('Vectorization orchestration failed:', error);\n    await logError(body.article_id, 'vectorize', String(error), env);\n    return new Response('Vectorization orchestration failed', { status: 500 });\n  }\n}\n\nasync function getStatus(body: TaskRequest, env: Env): Promise<Response> {\n  try {\n    const articleId = body.article_id;\n    if (!articleId) {\n      return new Response('Missing article_id', { status: 400 });\n    }\n    \n    const tasks = await env.DB.prepare(`\n      SELECT task_type, status, attempts, created_at, updated_at\n      FROM processing_queue \n      WHERE article_id = ?\n      ORDER BY created_at DESC\n      LIMIT 10\n    `).bind(articleId).all();\n    \n    return new Response(JSON.stringify({\n      article_id: articleId,\n      tasks: tasks.results\n    }), {\n      headers: { 'Content-Type': 'application/json' }\n    });\n  } catch (error) {\n    console.error('Status check failed:', error);\n    return new Response('Status check failed', { status: 500 });\n  }\n}\n\nasync function getMetrics(env: Env): Promise<Response> {\n  try {\n    const metrics = await env.DB.prepare(`\n      SELECT \n        task_type,\n        status,\n        COUNT(*) as count,\n        AVG(attempts) as avg_attempts\n      FROM processing_queue \n      WHERE created_at > datetime('now', '-24 hours')\n      GROUP BY task_type, status\n    `).all();\n    \n    const articleStats = await env.DB.prepare(`\n      SELECT \n        COUNT(*) as total_articles,\n        COUNT(CASE WHEN processed_at IS NOT NULL THEN 1 END) as processed_articles,\n        COUNT(CASE WHEN created_at > datetime('now', '-1 hour') THEN 1 END) as recent_articles\n      FROM articles\n    `).first();\n    \n    return new Response(JSON.stringify({\n      processing_metrics: metrics.results,\n      article_stats: articleStats,\n      timestamp: new Date().toISOString()\n    }), {\n      headers: { 'Content-Type': 'application/json' }\n    });\n  } catch (error) {\n    console.error('Metrics failed:', error);\n    return new Response('Metrics failed', { status: 500 });\n  }\n}\n\nasync function retryFailed(env: Env): Promise<Response> {\n  try {\n    // Get failed tasks from last 24 hours\n    const failedTasks = await env.DB.prepare(`\n      SELECT DISTINCT article_id, task_type\n      FROM processing_queue \n      WHERE status = 'failed' \n      AND attempts < 3\n      AND created_at > datetime('now', '-24 hours')\n      LIMIT 10\n    `).all();\n    \n    let retriedCount = 0;\n    \n    for (const task of failedTasks.results as any[]) {\n      try {\n        // Update attempt count\n        await env.DB.prepare(`\n          UPDATE processing_queue \n          SET attempts = attempts + 1, status = 'processing', updated_at = ?\n          WHERE article_id = ? AND task_type = ?\n        `).bind(\n          new Date().toISOString(),\n          task.article_id,\n          task.task_type\n        ).run();\n        \n        // Retry the task\n        const article = await env.DB.prepare(\n          'SELECT * FROM articles WHERE id = ?'\n        ).bind(task.article_id).first();\n        \n        if (article) {\n          switch (task.task_type) {\n            case 'extract':\n              await handleExtraction({\n                article_id: task.article_id,\n                url: (article as any).url,\n                source_name: (article as any).source_name\n              }, env);\n              break;\n            case 'process':\n              await handleProcessing({\n                article_id: task.article_id,\n                content_key: `articles/${task.article_id}.json`\n              }, env);\n              break;\n            case 'vectorize':\n              await handleVectorization({\n                article_id: task.article_id,\n                content_key: `articles/${task.article_id}.json`,\n                analysis_key: `analyses/${task.article_id}.json`\n              }, env);\n              break;\n          }\n          retriedCount++;\n        }\n      } catch (error) {\n        console.error(`Retry failed for article ${task.article_id}:`, error);\n      }\n    }\n    \n    return new Response(`Retried ${retriedCount} failed tasks`, { status: 200 });\n  } catch (error) {\n    console.error('Retry operation failed:', error);\n    return new Response('Retry operation failed', { status: 500 });\n  }\n}\n\nasync function logError(articleId: number | undefined, taskType: string, error: string, env: Env): Promise<void> {\n  try {\n    if (articleId) {\n      await env.DB.prepare(`\n        UPDATE processing_queue \n        SET status = 'failed', updated_at = ?\n        WHERE article_id = ? AND task_type = ?\n      `).bind(\n        new Date().toISOString(),\n        articleId,\n        taskType\n      ).run();\n    }\n    console.error(`Task ${taskType} failed for article ${articleId}:`, error);\n  } catch (logError) {\n    console.error('Failed to log error:', logError);\n  }\n}