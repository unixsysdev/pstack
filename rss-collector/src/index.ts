interface Env {\n  DB: D1Database;\n  ORCHESTRATOR_URL: string;\n}\n\ninterface RSSSource {\n  name: string;\n  rss_url: string;\n  main_url: string;\n  category: string;\n  update_frequency: string;\n  geo_focus: string[];\n  tags: string[];\n  access_method?: string;\n}\n\ninterface RSSItem {\n  title: string;\n  link: string;\n  description: string;\n  pubDate: string;\n  guid?: string;\n}\n\nconst RSS_FEEDS = [\n  {\n    \"name\": \"Defense One\",\n    \"rss_url\": \"https://www.defenseone.com/rss/all/\",\n    \"main_url\": \"https://www.defenseone.com\",\n    \"category\": \"defense_policy\",\n    \"update_frequency\": \"daily\",\n    \"geo_focus\": [\"US\", \"global\"],\n    \"tags\": [\"defense\", \"military\", \"pentagon\", \"technology\"]\n  }\n];\n\nexport default {\n  async scheduled(event: ScheduledEvent, env: Env, ctx: ExecutionContext): Promise<void> {\n    console.log('RSS Collector triggered at:', new Date().toISOString());\n    \n    for (const feed of RSS_FEEDS) {\n      try {\n        await processFeed(feed, env);\n      } catch (error) {\n        console.error(`Error processing feed ${feed.name}:`, error);\n      }\n    }\n  },\n\n  async fetch(request: Request, env: Env, ctx: ExecutionContext): Promise<Response> {\n    const url = new URL(request.url);\n    \n    if (url.pathname === '/trigger' && request.method === 'POST') {\n      // Manual trigger for testing\n      for (const feed of RSS_FEEDS) {\n        try {\n          await processFeed(feed, env);\n        } catch (error) {\n          console.error(`Error processing feed ${feed.name}:`, error);\n        }\n      }\n      return new Response('RSS collection triggered', { status: 200 });\n    }\n    \n    return new Response('RSS Collector Worker', { status: 200 });\n  }\n} satisfies ExportedHandler<Env>;\n\nasync function processFeed(source: RSSSource, env: Env): Promise<void> {\n  try {\n    let feedData: any;\n    \n    if (source.access_method === 'RSS2JSON') {\n      // Handle RSS2JSON sources\n      const response = await fetch(source.rss_url);\n      feedData = await response.json();\n      \n      if (feedData.items) {\n        for (const item of feedData.items) {\n          await processItem({\n            title: item.title,\n            link: item.link,\n            description: item.description || '',\n            pubDate: item.pubDate || new Date().toISOString(),\n            guid: item.guid\n          }, source, env);\n        }\n      }\n    } else {\n      // Handle regular RSS feeds\n      const response = await fetch(source.rss_url);\n      const rssText = await response.text();\n      \n      // Simple RSS parsing\n      const items = parseRSSItems(rssText);\n      \n      for (const item of items) {\n        await processItem(item, source, env);\n      }\n    }\n  } catch (error) {\n    console.error(`Failed to process feed ${source.name}:`, error);\n  }\n}\n\nfunction parseRSSItems(rssText: string): RSSItem[] {\n  const items: RSSItem[] = [];\n  const itemRegex = /<item[^>]*>([\\s\\S]*?)<\\/item>/gi;\n  let match;\n  \n  while ((match = itemRegex.exec(rssText)) !== null) {\n    const itemContent = match[1];\n    \n    const title = extractTag(itemContent, 'title');\n    const link = extractTag(itemContent, 'link');\n    const description = extractTag(itemContent, 'description');\n    const pubDate = extractTag(itemContent, 'pubDate');\n    const guid = extractTag(itemContent, 'guid');\n    \n    if (title && link) {\n      items.push({\n        title: title.trim(),\n        link: link.trim(),\n        description: description?.trim() || '',\n        pubDate: pubDate?.trim() || new Date().toISOString(),\n        guid: guid?.trim()\n      });\n    }\n  }\n  \n  return items;\n}\n\nfunction extractTag(content: string, tagName: string): string | null {\n  const regex = new RegExp(`<${tagName}[^>]*>([\\s\\S]*?)<\\/${tagName}>`, 'i');\n  const match = regex.exec(content);\n  if (match) {\n    return match[1].replace(/<\\!\\[CDATA\\[(.*?)\\]\\]>/g, '$1');\n  }\n  return null;\n}\n\nasync function processItem(item: RSSItem, source: RSSSource, env: Env): Promise<void> {\n  try {\n    // Check if article already exists\n    const existing = await env.DB.prepare(\n      'SELECT id FROM articles WHERE url = ?'\n    ).bind(item.link).first();\n    \n    if (existing) {\n      return; // Already processed\n    }\n    \n    // Insert new article\n    const result = await env.DB.prepare(`\n      INSERT INTO articles (url, title, description, published_at, source_name, category, tags, created_at)\n      VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n    `).bind(\n      item.link,\n      item.title,\n      item.description,\n      new Date(item.pubDate).toISOString(),\n      source.name,\n      source.category,\n      JSON.stringify(source.tags),\n      new Date().toISOString()\n    ).run();\n    \n    if (result.success && result.meta.last_row_id) {\n      // Trigger content extraction\n      await fetch(env.ORCHESTRATOR_URL + '/extract', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          article_id: result.meta.last_row_id,\n          url: item.link,\n          source_name: source.name\n        })\n      });\n    }\n  } catch (error) {\n    console.error('Error processing item:', error);\n  }\n}