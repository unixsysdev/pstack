interface Env {\n  DB: D1Database;\n  CONTENT_BUCKET: R2Bucket;\n  BROWSER: Fetcher;\n  ORCHESTRATOR_URL: string;\n}\n\ninterface ExtractionRequest {\n  article_id: number;\n  url: string;\n  source_name: string;\n}\n\nexport default {\n  async fetch(request: Request, env: Env, ctx: ExecutionContext): Promise<Response> {\n    const url = new URL(request.url);\n    \n    if (url.pathname === '/extract' && request.method === 'POST') {\n      try {\n        const body: ExtractionRequest = await request.json();\n        await extractContent(body, env);\n        return new Response('Content extraction initiated', { status: 200 });\n      } catch (error) {\n        console.error('Extraction error:', error);\n        return new Response('Extraction failed', { status: 500 });\n      }\n    }\n    \n    if (url.pathname === '/health') {\n      return new Response('Content Extractor OK', { status: 200 });\n    }\n    \n    return new Response('Content Extractor Worker', { status: 200 });\n  }\n} satisfies ExportedHandler<Env>;\n\nasync function extractContent(req: ExtractionRequest, env: Env): Promise<void> {\n  try {\n    // Get article details\n    const article = await env.DB.prepare(\n      'SELECT * FROM articles WHERE id = ?'\n    ).bind(req.article_id).first();\n    \n    if (!article) {\n      console.error('Article not found:', req.article_id);\n      return;\n    }\n    \n    // Use Cloudflare Browser Rendering to extract content\n    const response = await env.BROWSER.fetch('https://cloudflare.com/browser-rendering', {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json'\n      },\n      body: JSON.stringify({\n        cmd: 'session.new',\n        url: req.url,\n        actions: [\n          {\n            type: 'wait',\n            selector: 'body',\n            timeout: 10000\n          },\n          {\n            type: 'extract',\n            selectors: {\n              title: 'h1, .title, [class*=\"title\"], [class*=\"headline\"]',\n              content: 'article, .content, .post-content, .entry-content, [class*=\"content\"], main, .main',\n              publishDate: '[class*=\"date\"], time, .published',\n              author: '.author, [class*=\"author\"], .byline'\n            }\n          }\n        ]\n      })\n    });\n    \n    if (!response.ok) {\n      console.error('Browser rendering failed:', await response.text());\n      return;\n    }\n    \n    const result = await response.json();\n    let extractedContent = '';\n    let cleanTitle = article.title;\n    \n    if (result.data && result.data.content) {\n      // Clean extracted content\n      extractedContent = cleanContent(result.data.content);\n      \n      // Use extracted title if available\n      if (result.data.title && result.data.title.trim()) {\n        cleanTitle = result.data.title.trim();\n      }\n    } else {\n      // Fallback: simple fetch and basic extraction\n      console.log('Browser rendering failed, using fallback method');\n      const fallbackResponse = await fetch(req.url, {\n        headers: {\n          'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n        }\n      });\n      \n      if (fallbackResponse.ok) {\n        const html = await fallbackResponse.text();\n        extractedContent = extractContentFromHTML(html);\n      }\n    }\n    \n    if (extractedContent && extractedContent.length > 100) {\n      // Store full content in R2\n      const contentKey = `articles/${req.article_id}.json`;\n      const contentData = {\n        article_id: req.article_id,\n        url: req.url,\n        title: cleanTitle,\n        content: extractedContent,\n        extracted_at: new Date().toISOString(),\n        source_name: req.source_name,\n        word_count: extractedContent.split(' ').length\n      };\n      \n      await env.CONTENT_BUCKET.put(contentKey, JSON.stringify(contentData, null, 2), {\n        httpMetadata: {\n          contentType: 'application/json'\n        }\n      });\n      \n      // Update article in DB\n      await env.DB.prepare(`\n        UPDATE articles \n        SET content = ?, processed_at = ?, updated_at = ?\n        WHERE id = ?\n      `).bind(\n        extractedContent.substring(0, 1000), // Store first 1000 chars in DB\n        new Date().toISOString(),\n        new Date().toISOString(),\n        req.article_id\n      ).run();\n      \n      // Trigger AI processing\n      await fetch(env.ORCHESTRATOR_URL + '/process', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          article_id: req.article_id,\n          content_key: contentKey\n        })\n      });\n      \n      console.log(`Content extracted for article ${req.article_id}: ${extractedContent.length} chars`);\n    } else {\n      console.error('No meaningful content extracted for:', req.url);\n    }\n  } catch (error) {\n    console.error('Content extraction failed:', error);\n  }\n}\n\nfunction cleanContent(rawContent: string): string {\n  if (!rawContent) return '';\n  \n  return rawContent\n    .replace(/<script[^>]*>[\\s\\S]*?<\\/script>/gi, '')\n    .replace(/<style[^>]*>[\\s\\S]*?<\\/style>/gi, '')\n    .replace(/<nav[^>]*>[\\s\\S]*?<\\/nav>/gi, '')\n    .replace(/<footer[^>]*>[\\s\\S]*?<\\/footer>/gi, '')\n    .replace(/<aside[^>]*>[\\s\\S]*?<\\/aside>/gi, '')\n    .replace(/<header[^>]*>[\\s\\S]*?<\\/header>/gi, '')\n    .replace(/<[^>]+>/g, ' ')\n    .replace(/\\s+/g, ' ')\n    .replace(/&nbsp;/g, ' ')\n    .replace(/&amp;/g, '&')\n    .replace(/&lt;/g, '<')\n    .replace(/&gt;/g, '>')\n    .replace(/&quot;/g, '\"')\n    .trim();\n}\n\nfunction extractContentFromHTML(html: string): string {\n  // Basic HTML content extraction as fallback\n  const contentSelectors = [\n    /<article[^>]*>([\\s\\S]*?)<\\/article>/gi,\n    /<div[^>]*class[^>]*content[^>]*>([\\s\\S]*?)<\\/div>/gi,\n    /<main[^>]*>([\\s\\S]*?)<\\/main>/gi\n  ];\n  \n  for (const selector of contentSelectors) {\n    const match = selector.exec(html);\n    if (match && match[1]) {\n      return cleanContent(match[1]);\n    }\n  }\n  \n  // Last resort: extract from body\n  const bodyMatch = /<body[^>]*>([\\s\\S]*?)<\\/body>/gi.exec(html);\n  if (bodyMatch && bodyMatch[1]) {\n    return cleanContent(bodyMatch[1]).substring(0, 5000);\n  }\n  \n  return '';\n}